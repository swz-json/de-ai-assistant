<div align="center">

# DE AI Assistant

**An Agentic RAG platform for Data Engineering.**<br>
*Capable of executing SQL, debugging pipelines, and generating context-aware code.*

[![Status](https://img.shields.io/badge/Status-Production_Ready-success.svg)]()
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Stack](https://img.shields.io/badge/Stack-FastAPI_|_SQL_Server_|_Ollama-purple)]()
[![License](https://img.shields.io/badge/license-MIT-green.svg)]()
[![Docker](https://img.shields.io/badge/Docker-Coming_Soon-orange)]()

[English](README.md) | [Documentation](docs/README_DOCS.md) | [Architecture](docs/ARCHITECTURE.md)

<img width="1902" height="912" alt="dataais" src="https://github.com/user-attachments/assets/44b8d58d-2347-41e0-8269-8107d67a0bb9" />



</div>

## üìã Requirements

- **Python:** 3.10 or higher
- **Database:** Microsoft SQL Server (Local or Azure)
- **LLM Engine:** Ollama (running `qwen2.5` or `llama3`)
- **Driver:** ODBC Driver 17 for SQL Server
- **Vector Store:** ChromaDB (Embedded)

## ‚ö° Capabilities Matrix

| Feature | Description | Status |
| :--- | :--- | :---: |
| **Schema Awareness** | Reads `sys.tables` to understand your specific DB structure | ‚úÖ |
| **Autonomous Agent** | Can safely execute read-only SQL queries via UI | ‚úÖ |
| **RAG System** | Retrieves context from internal runbooks/docs | ‚úÖ |
| **Streaming** | Real-time token generation (ChatGPT-style) | ‚úÖ |
| **Memory** | Persists conversation history in SQL Server | ‚úÖ |
| **Privacy** | 100% Local inference (No data leaves your network) | ‚úÖ |

## üöÄ Installation

### 1. Clone the repository
```bash
git clone [https://github.com/yourusername/de-ai-assistant.git](https://github.com/yourusername/de-ai-assistant.git)
cd de-ai-assistant
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Configure Environment
```bash
MSSQL_CONN_STR="Driver={ODBC Driver 17 for SQL Server};Server=YOUR_SERVER;Database=DeAiAssistant;Trusted_Connection=yes;"
OLLAMA_URL="[http://127.0.0.1:11434](http://127.0.0.1:11434)"
OLLAMA_MODEL="qwen2.5:7b"
```


## üíª Usage
### Start the Server
#### Run the FastAPI backend with Uvicorn:
```bash
uvicorn app.api.main:app --reload
```

## Access the Interface
+ Open your browser and navigate to: http://localhost:8000

## Agent Commands
### The assistant supports natural language, but also specific agentic triggers:

+ "Count records in [table]..." ‚Üí Triggers SQL generation.

+ "Debug this error..." ‚Üí Triggers RAG lookup.

+ "Write a dbt model..." ‚Üí Triggers code generation mode.

## üèóÔ∏è Architecture
### The system follows a modern **Agentic RAG** architecture:

**1.** **User Input:** Captured via Vanilla JS Frontend.

**2.** **Router:** FastAPI determines intent (SQL vs. Chat vs. Code).

**3.** **Context Injection:**

   **+ Memory:** Fetches last 10 messages from SQL Server.
 
   **+ Schema:** Queries live DB metadata.
 
  **+ Docs:** Queries ChromaDB vector store.


**4.** **Inference:** Ollama processes the prompt + context.

**5.** **Execution (Optional):** If SQL is generated, the "Run Query" button becomes active.



